{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# ROOT_DIR = '../data/images'\n",
    "TRAIN_DIR = '../train-data'\n",
    "TEST_DIR = '../test-data'\n",
    "input_shape = (32, 32, 1)\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        640       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 32)        18464     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,435\n",
      "Trainable params: 150,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Fit to input size\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    mapper = {'blank': 0, 'nough': 1, 'circle': 2}\n",
    "    encoded = [mapper[label] for label in labels]\n",
    "    target = to_categorical(encoded)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_dir, shuffle=True):\n",
    "    X, y = [], []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for class_dir in dirs:\n",
    "            image_dir = os.path.join(root_dir, class_dir)\n",
    "            y.extend(np.tile(class_dir, len(os.listdir(image_dir))))\n",
    "            for img_fn in os.listdir(image_dir):\n",
    "                img = load_img(os.path.join(image_dir, img_fn))\n",
    "                X.append(img)\n",
    "    y = one_hot_encode(y)\n",
    "    if shuffle:\n",
    "        # Combine to maintain order\n",
    "        data = list(zip(X, y))\n",
    "        np.random.shuffle(data)\n",
    "        X, y = zip(*data)\n",
    "    return np.asarray(X), np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "480 instances for training\n",
      "120 instances for evaluation\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "X_train, y_train = load_data(TRAIN_DIR)\n",
    "X_test, y_test = load_data(TEST_DIR)\n",
    "print('{} instances for training'.format(len(X_train)))\n",
    "print('{} instances for evaluation'.format(len(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create more instances since our dataset is VERY limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=90,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1 / 255,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = train_val_datagen.flow(\n",
    "    X_train, y_train, batch_size=batch_size, subset='training')\n",
    "\n",
    "val_generator = train_val_datagen.flow(\n",
    "    X_train, y_train, batch_size=batch_size, subset='validation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5863/1771159742.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n",
      "2023-05-01 09:36:44.861645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/128 [=>............................] - ETA: 2s - loss: 0.9497 - accuracy: 0.5031WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3840 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset.\n",
      "128/128 [==============================] - 1s 3ms/step - loss: 0.9274 - accuracy: 0.5182 - val_loss: 0.6850 - val_accuracy: 0.6979\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 09:36:45.438003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=5, verbose=1, restore_best_weights=True)]\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=128,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "print('Evaluating model...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7125 - accuracy: 0.6500\n",
      "Crossentropy loss: 0.713\n",
      "Accuracy: 0.650\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "X_test, y_test = next(test_datagen.flow(X_test, y_test, batch_size=len(X_test)))\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Crossentropy loss: {:0.3f}'.format(loss))\n",
    "print('Accuracy: {:0.3f}'.format(acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('../model.h5')\n",
    "print('Saved model to disk')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tic-tac-toe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
